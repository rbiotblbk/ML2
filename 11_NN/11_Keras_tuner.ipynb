{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner 2024\n",
    "\n",
    "to test and search for the best architecture and hyper parameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python\\Python3116\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import keras_tuner\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:-10000]\n",
    "x_val = x[-10000:]\n",
    "y_train = y[:-10000]\n",
    "y_val = y[-10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Layer preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. With static count of hidden layers -> 1x hidden layer with dyanmic count of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512,step=32), # tune the count of neorons\n",
    "\n",
    "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]) # tune the activation function\n",
    "\n",
    "        ))\n",
    "\n",
    "\n",
    "\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "    model.add(layers.Dense(10,activation=\"softmax\"))  # Output Layer\n",
    "\n",
    "    # Dynamic LR\n",
    "    learning_rate  =  hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. With dynamic count of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "    # tune the counf of the hidden layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512,step=32), # tune the count of neorons\n",
    "\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]) # tune the activation function\n",
    "\n",
    "            ))\n",
    "\n",
    "\n",
    "\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "    model.add(layers.Dense(10,activation=\"softmax\"))  # Output Layer\n",
    "\n",
    "    # Dynamic LR\n",
    "    learning_rate  =  hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the build_model working with hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python\\Python3116\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x203b34f7050>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "\n",
    "build_model(hp)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=2, # combinatin of params\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"keras_tuner\",\n",
    "    project_name=\"MyTuner1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 01m 15s]\n",
      "val_accuracy: 0.9754500091075897\n",
      "\n",
      "Best val_accuracy So Far: 0.9754500091075897\n",
      "Total elapsed time: 00h 01m 55s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Result Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in keras_tuner\\MyTuner1\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 352\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.0014835474564790457\n",
      "units_1: 96\n",
      "units_2: 32\n",
      "Score: 0.9754500091075897\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 32\n",
      "activation: tanh\n",
      "dropout: True\n",
      "lr: 0.0008711452772441899\n",
      "units_1: 32\n",
      "Score: 0.9625999927520752\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the best Hyper Paramter to retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2141 - accuracy: 0.9359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x203c0e2a590>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps  = tuner.get_best_hyperparameters(3) # get a list of top 3 hp\n",
    "best_hps  = tuner.get_best_hyperparameters() # get a list of top 1 hp\n",
    "\n",
    "model = build_model(best_hps[0]) # [0]get the top best hp and build the model\n",
    "\n",
    "# Fit the model with the entire dataset\n",
    "x_all = np.concatenate((x_train, x_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "\n",
    "model.fit(x=x_all, y=y_all, epochs= 1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
